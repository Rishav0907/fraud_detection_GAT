{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "731220e2-b0c3-4d33-a715-d1340afc6617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import Linear, LayerNorm, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv,GATConv,GATv2Conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5faabd02-ee59-4bac-a7f2-d4f67dc01489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from the folder\n",
    "FOLDERNAME=\"bitcoin_dataset/\"\n",
    "df_features = pd.read_csv(FOLDERNAME+'elliptic_txs_features.csv',header=None)\n",
    "df_edges = pd.read_csv(FOLDERNAME+\"elliptic_txs_edgelist.csv\")\n",
    "df_classes =  pd.read_csv(FOLDERNAME+\"elliptic_txs_classes.csv\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4123a92f-1063-458c-a1d4-b67ea44db587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add class names for easy understanding\n",
    "# reformat classes 0:licit, 1:illicit, 2:unknow \n",
    "df_classes['class'] = df_classes['class'].map({'unknown': 2, '1':1, '2':0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62df3e5c-46bb-4924-a860-0ae385d2b292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See repartition of nodes per class\n",
    "group_class = df_classes.groupby('class').count()\n",
    "plt.title(\"# of nodes per class\")\n",
    "plt.barh([ 'Licit','Illicit', 'Unknown'], group_class['txId'].values, color=['g', 'orange', 'r'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "462644c1-c75e-4b66-93dd-15d51885984e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>txId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1076</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.168500</td>\n",
       "      <td>0.270909</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.046932</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.029140</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163591</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461330</td>\n",
       "      <td>1.461369</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.470019</td>\n",
       "      <td>1.216796</td>\n",
       "      <td>1.151607</td>\n",
       "      <td>1.519700</td>\n",
       "      <td>1.521399</td>\n",
       "      <td>1076</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2534</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.170834</td>\n",
       "      <td>-0.131425</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.055376</td>\n",
       "      <td>0.054722</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955101</td>\n",
       "      <td>0.459257</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.099080</td>\n",
       "      <td>-0.122137</td>\n",
       "      <td>-0.379970</td>\n",
       "      <td>-0.379288</td>\n",
       "      <td>2534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3181</td>\n",
       "      <td>34</td>\n",
       "      <td>1.305212</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>97.300650</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>1.348765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.113967</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>1.969527</td>\n",
       "      <td>0.037532</td>\n",
       "      <td>-0.131010</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>3181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3321</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241128</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.084674</td>\n",
       "      <td>-0.140597</td>\n",
       "      <td>1.519700</td>\n",
       "      <td>1.521399</td>\n",
       "      <td>3321</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3889</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.086232</td>\n",
       "      <td>-0.101835</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>17.046997</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.074885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082065</td>\n",
       "      <td>0.114773</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>8.948005</td>\n",
       "      <td>1.024948</td>\n",
       "      <td>-0.009570</td>\n",
       "      <td>-0.080708</td>\n",
       "      <td>-0.123601</td>\n",
       "      <td>3889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1         2         3         4         5          6         7  \\\n",
       "0  1076  48 -0.168500  0.270909 -0.091383 -0.046932  -0.043875 -0.029140   \n",
       "1  2534   6 -0.170834 -0.131425  1.018602  0.028105   0.055376  0.054722   \n",
       "2  3181  34  1.305212 -0.210553 -1.756361 -0.121970  97.300650 -0.113002   \n",
       "3  3321   1 -0.169615 -0.184668 -1.201369 -0.121970  -0.043875 -0.113002   \n",
       "4  3889  48 -0.086232 -0.101835 -0.646376 -0.121970  17.046997 -0.113002   \n",
       "\n",
       "          8         9  ...       159       160       161       162       163  \\\n",
       "0 -0.061584 -0.163591  ...  1.461330  1.461369  0.018279  0.470019  1.216796   \n",
       "1 -0.061584 -0.163572  ...  0.955101  0.459257 -0.098889 -0.087490 -0.099080   \n",
       "2 -0.061584  1.348765  ...  0.059948  0.113967 -0.098889  1.969527  0.037532   \n",
       "3 -0.061584 -0.160199  ...  0.241128  0.241406 -0.098889 -0.087490 -0.084674   \n",
       "4 -0.061584 -0.074885  ...  0.082065  0.114773 -0.098889  8.948005  1.024948   \n",
       "\n",
       "        164       165       166  txId  class  \n",
       "0  1.151607  1.519700  1.521399  1076      2  \n",
       "1 -0.122137 -0.379970 -0.379288  2534      0  \n",
       "2 -0.131010  0.006994  0.017772  3181      0  \n",
       "3 -0.140597  1.519700  1.521399  3321      2  \n",
       "4 -0.009570 -0.080708 -0.123601  3889      2  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge features with classes\n",
    "df_merge = df_features.merge(df_classes, how='left', right_on=\"txId\", left_on=0)\n",
    "df_merge = df_merge.sort_values(0).reset_index(drop=True)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bfef597-e17b-44d3-9c93-9dd2407e6232",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of edge index is torch.Size([2, 234355])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[138670., 141325., 139232.,  ..., 100420.,  54833., 101159.],\n",
       "        [  4142., 142201., 139223.,  ..., 100419.,  81951., 101163.]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup trans ID to node ID mapping\n",
    "nodes = df_merge[0].values\n",
    "\n",
    "map_id = {j:i for i,j in enumerate(nodes)} # mapping nodes to indexes\n",
    "\n",
    "# Create edge df that has transID mapped to nodeIDs\n",
    "edges = df_edges.copy()\n",
    "edges.txId1 = edges.txId1.map(map_id) #get nodes idx1 from edges list and filtered data\n",
    "edges.txId2 = edges.txId2.map(map_id)\n",
    "\n",
    "edges = edges.astype(int)\n",
    "\n",
    "edge_index = np.array(edges.values).T #convert into an array\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.double).contiguous() # create a tensor\n",
    "\n",
    "print(\"shape of edge index is {}\".format(edge_index.shape))\n",
    "edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "180d4ca4-98e6-44d2-b005-2a54897684f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create weights tensor with same shape of edge_index\n",
    "weights = torch.tensor([1]* edge_index.shape[1] , dtype=torch.double) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a824718-6866-478c-a843-59c294a64b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lables [0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define labels\n",
    "labels = df_merge['class'].values\n",
    "print(\"lables\", np.unique(labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25ddbbfa-2be3-492e-b545-8ff8a131bf78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique= [2 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1685,  0.2709, -0.0914,  ...,  1.1516,  1.5197,  1.5214],\n",
       "        [-0.1708, -0.1314,  1.0186,  ..., -0.1221, -0.3800, -0.3793],\n",
       "        [ 1.3052, -0.2106, -1.7564,  ..., -0.1310,  0.0070,  0.0178],\n",
       "        ...,\n",
       "        [-0.1727, -0.1588, -1.2014,  ..., -0.2698, -0.1206, -0.1198],\n",
       "        [-0.1727, -0.1588, -1.2014,  ..., -0.2698, -0.1206, -0.1198],\n",
       "        [-0.1433, -0.1588, -1.2014,  ..., -0.0975, -0.1206, -0.1198]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping txIds to corresponding indices, to pass node features to the model\n",
    "\n",
    "node_features = df_merge.drop(['txId'], axis=1).copy()\n",
    "# node_features[0] = node_features[0].map(map_id) # Convert transaction ID to node ID \\\n",
    "print(\"unique=\",node_features[\"class\"].unique())\n",
    "\n",
    "# Retain known vs unknown IDs\n",
    "classified_idx = node_features['class'].loc[node_features['class']!=2].index # filter on known labels\n",
    "unclassified_idx = node_features['class'].loc[node_features['class']==2].index\n",
    "\n",
    "classified_illicit_idx = node_features['class'].loc[node_features['class']==1].index # filter on illicit labels\n",
    "classified_licit_idx = node_features['class'].loc[node_features['class']==0].index # filter on licit labels\n",
    "\n",
    "# Drop unwanted columns, 0 = transID, 1=time period, class = labels\n",
    "node_features = node_features.drop(columns=[0, 1, 'class'])\n",
    "\n",
    "# Convert to tensor\n",
    "node_features_t = torch.tensor(np.array(node_features.values, dtype=np.double), dtype=torch.double)# drop unused columns\n",
    "node_features_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18e2836e-873c-4457-8235-1231e4f3d5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_idx size 39579\n",
      "tets_idx size 6985\n"
     ]
    }
   ],
   "source": [
    "# Create a known vs unknown mask\n",
    "train_idx, valid_idx = train_test_split(classified_idx.values, test_size=0.15)\n",
    "print(\"train_idx size {}\".format(len(train_idx)))\n",
    "print(\"tets_idx size {}\".format(len(valid_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b977243-3477-49a9-8578-356440442548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = Data(x=node_features_t, edge_index=edge_index, edge_attr=weights, \n",
    "                               y=torch.tensor(labels, dtype=torch.double))\n",
    "# Add in the train and valid idx\n",
    "data_train.train_idx = train_idx\n",
    "data_train.valid_idx = valid_idx\n",
    "data_train.test_idx = unclassified_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d60bdc5-31dc-4625-a37a-321151ee6b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Union, Tuple, Optional\n",
    "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
    "                                    OptTensor)\n",
    "\n",
    "from torch.nn import Parameter, Linear\n",
    "from torch_sparse import SparseTensor, set_diag\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax, degree\n",
    "\n",
    "from torch_geometric.nn import GCNConv,GATConv,GATv2Conv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ee2f39a-8081-4660-8e24-056ef9c271f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self,input_dim, hidden_dim, output_dim,args):\n",
    "        super(GAT, self).__init__()\n",
    "        #use our gat message passing \n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=args['heads'])\n",
    "        self.conv2 = GATConv(args['heads'] * hidden_dim, hidden_dim, heads=args['heads'])\n",
    "        \n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(args['heads'] * hidden_dim, hidden_dim), nn.Dropout(args['dropout'] ), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "    def forward(self, data, adj=None):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # Layer 1\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.dropout(F.relu(x), p=args['dropout'], training=self.training)\n",
    "        # Layer 2\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.dropout(F.relu(x), p=args['dropout'], training=self.training)\n",
    "        # MLP output\n",
    "        x = self.post_mp(x)\n",
    "        return F.sigmoid(x)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "150007a7-2e66-4d98-9e59-fed6232d9e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GnnTrainer(object):\n",
    "  \n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "    self.metric_manager = MetricManager(modes=[\"train\", \"val\"])\n",
    "\n",
    "  def train(self, data_train, optimizer, criterion, scheduler, args):\n",
    "  \n",
    "    self.data_train = data_train\n",
    "    for epoch in range(args['epochs']):\n",
    "        self.model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = self.model(data_train)\n",
    "\n",
    "        out = out.reshape((data_train.x.shape[0]))\n",
    "        loss = criterion(out[data_train.train_idx], data_train.y[data_train.train_idx])\n",
    "        ## Metric calculations\n",
    "        # train data\n",
    "        target_labels = data_train.y.detach().cpu().numpy()[data_train.train_idx]\n",
    "        pred_scores = out.detach().cpu().numpy()[data_train.train_idx]\n",
    "        train_acc, train_f1,train_f1macro, train_aucroc, train_recall, train_precision, train_cm = self.metric_manager.store_metrics(\"train\", pred_scores, target_labels)\n",
    "\n",
    "\n",
    "        ## Training Step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # validation data\n",
    "        self.model.eval()\n",
    "        target_labels = data_train.y.detach().cpu().numpy()[data_train.valid_idx]\n",
    "        pred_scores = out.detach().cpu().numpy()[data_train.valid_idx]\n",
    "        val_acc, val_f1,val_f1macro, val_aucroc, val_recall, val_precision, val_cm = self.metric_manager.store_metrics(\"val\", pred_scores, target_labels)\n",
    "\n",
    "        if epoch%5 == 0:\n",
    "          print(\"epoch: {} - loss: {:.4f} - accuracy train: {:.4f} -accuracy valid: {:.4f}  - val roc: {:.4f}  - val f1micro: {:.4f}\".format(epoch, loss.item(), train_acc, val_acc, val_aucroc,val_f1))\n",
    "\n",
    "  # To predict labels\n",
    "  def predict(self, data=None, unclassified_only=True, threshold=0.5):\n",
    "    # evaluate model:\n",
    "    self.model.eval()\n",
    "    if data is not None:\n",
    "      self.data_train = data\n",
    "\n",
    "    out = self.model(self.data_train)\n",
    "    out = out.reshape((self.data_train.x.shape[0]))\n",
    "\n",
    "    if unclassified_only:\n",
    "      pred_scores = out.detach().cpu().numpy()[self.data_train.test_idx]\n",
    "    else:\n",
    "      pred_scores = out.detach().cpu().numpy()\n",
    "\n",
    "    pred_labels = pred_scores > threshold\n",
    "\n",
    "    return {\"pred_scores\":pred_scores, \"pred_labels\":pred_labels}\n",
    "\n",
    "  # To save metrics\n",
    "  def save_metrics(self, save_name, path=\"./save/\"):\n",
    "    file_to_store = open(path + save_name, \"wb\")\n",
    "    pickle.dump(self.metric_manager, file_to_store)\n",
    "    file_to_store.close()\n",
    "  \n",
    "  # To save model\n",
    "  def save_model(self, save_name, path=\"./save/\"):\n",
    "    torch.save(self.model.state_dict(), path + save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d3f4f3b-140f-474c-b50a-5c4640dd5154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetricManager(object):\n",
    "  def __init__(self, modes=[\"train\", \"val\"]):\n",
    "\n",
    "    self.output = {}\n",
    "\n",
    "    for mode in modes:\n",
    "      self.output[mode] = {}\n",
    "      self.output[mode][\"accuracy\"] = []\n",
    "      self.output[mode][\"f1micro\"] = []\n",
    "      self.output[mode][\"f1macro\"] = []\n",
    "      self.output[mode][\"aucroc\"] = []\n",
    "      #new\n",
    "      self.output[mode][\"precision\"] = []\n",
    "      self.output[mode][\"recall\"] = []\n",
    "      self.output[mode][\"cm\"] = []\n",
    "\n",
    "  def store_metrics(self, mode, pred_scores, target_labels, threshold=0.5):\n",
    "\n",
    "    # calculate metrics\n",
    "    pred_labels = pred_scores > threshold\n",
    "    accuracy = accuracy_score(target_labels, pred_labels)\n",
    "    f1micro = f1_score(target_labels, pred_labels,average='micro')\n",
    "    f1macro = f1_score(target_labels, pred_labels,average='macro')\n",
    "    aucroc = roc_auc_score(target_labels, pred_scores)\n",
    "    #new\n",
    "    recall = recall_score(target_labels, pred_labels)\n",
    "    precision = precision_score(target_labels, pred_labels)\n",
    "    cm = confusion_matrix(target_labels, pred_labels)\n",
    "\n",
    "    # Collect results\n",
    "    self.output[mode][\"accuracy\"].append(accuracy)\n",
    "    self.output[mode][\"f1micro\"].append(f1micro)\n",
    "    self.output[mode][\"f1macro\"].append(f1macro)\n",
    "    self.output[mode][\"aucroc\"].append(aucroc)\n",
    "    #new\n",
    "    self.output[mode][\"recall\"].append(recall)\n",
    "    self.output[mode][\"precision\"].append(precision)\n",
    "    self.output[mode][\"cm\"].append(cm)\n",
    "    \n",
    "    return accuracy, f1micro,f1macro, aucroc,recall,precision,cm\n",
    "  \n",
    "  # Get best results\n",
    "  def get_best(self, metric, mode=\"val\"):\n",
    "\n",
    "    # Get best results index\n",
    "    best_results = {}\n",
    "    i = np.array(self.output[mode][metric]).argmax()\n",
    "\n",
    "    # Output\n",
    "    for m in self.output[mode].keys():\n",
    "      best_results[m] = self.output[mode][m][i]\n",
    "    \n",
    "    return best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70b066a6-2b3e-4aa0-b850-e6c847927992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set training arguments, set prebuild=True to use builtin PyG models otherwise False\n",
    "args={\"epochs\":100,\n",
    "      'lr':0.01,\n",
    "      'weight_decay':1e-5,\n",
    "      'prebuild':True,\n",
    "      'heads':2,\n",
    "      'hidden_dim': 128, \n",
    "      'dropout': 0.5\n",
    "      }\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dcaf9e61-a9eb-4986-8dc6-9d37540d1002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GAT(data_train.num_node_features, args['hidden_dim'], 1, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54f83339-0e66-41fb-8afd-eb404bdab8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: double != float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m     10\u001b[0m gnn_trainer_gat \u001b[38;5;241m=\u001b[39m GnnTrainer(model)\n\u001b[1;32m---> 11\u001b[0m gnn_trainer_gat\u001b[38;5;241m.\u001b[39mtrain(data_train, optimizer, criterion, scheduler, args)\n\u001b[0;32m     13\u001b[0m gnn_trainer_gat\u001b[38;5;241m.\u001b[39msave_metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGATprebuilt.results\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39mFOLDERNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/save_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m gnn_trainer_gat\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGATprebuilt.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39mFOLDERNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/save_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[52], line 13\u001b[0m, in \u001b[0;36mGnnTrainer.train\u001b[1;34m(self, data_train, optimizer, criterion, scheduler, args)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data_train)\n\u001b[0;32m     15\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mreshape((data_train\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out[data_train\u001b[38;5;241m.\u001b[39mtrain_idx], data_train\u001b[38;5;241m.\u001b[39my[data_train\u001b[38;5;241m.\u001b[39mtrain_idx])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[51], line 15\u001b[0m, in \u001b[0;36mGAT.forward\u001b[1;34m(self, data, adj)\u001b[0m\n\u001b[0;32m     13\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Layer 1\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(F\u001b[38;5;241m.\u001b[39mrelu(x), p\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Layer 2\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:280\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatic graphs not supported in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGATConv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m     x_src \u001b[38;5;241m=\u001b[39m x_dst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, C)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# If the module is initialized as bipartite, transform source\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# and destination node features separately:\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_src \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_dst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: double != float"
     ]
    }
   ],
   "source": [
    "# Push data to GPU\n",
    "# data_train = data_train.to(device)\n",
    "\n",
    "# Setup training settings\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Train\n",
    "gnn_trainer_gat = GnnTrainer(model)\n",
    "gnn_trainer_gat.train(data_train, optimizer, criterion, scheduler, args)\n",
    "\n",
    "gnn_trainer_gat.save_metrics(\"GATprebuilt.results\", path=FOLDERNAME + \"/save_results/\")\n",
    "gnn_trainer_gat.save_model(\"GATprebuilt.pth\", path=FOLDERNAME + \"/save_results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd43b9-364b-439a-bbc4-0fa19b274529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208ff15-42f7-48cf-94a8-1b78e76475ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822a066-5190-41a5-a0ce-9c86054ff5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
